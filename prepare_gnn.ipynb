{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_graphml(\"graph.graphml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node labels: {':Movie', ':Person', ':Cinema'}\n",
      "Edge labels: {'PRODUCED', 'RELEASED', 'ACTED_IN', 'REVIEWED', 'DIRECTED', 'WROTE', 'FOLLOWS'}\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”¥ Step 2: Identify Node and Edge Types\n",
    "node_labels = set(nx.get_node_attributes(G, \"label\").values())  # Extract unique node labels\n",
    "edge_labels = set((G[u][v][\"label\"] for u, v in G.edges if \"label\" in G[u][v]))  # Unique edge labels\n",
    "\n",
    "print(f\"Node labels: {node_labels}\")\n",
    "print(f\"Edge labels: {edge_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¥ Step 3: Process Nodes and Convert to PyTorch Format\n",
    "data = HeteroData()\n",
    "\n",
    "# Store node index mappings\n",
    "node_mappings = {}  # {node_label: {original_id: new_index}}\n",
    "\n",
    "for node_label in node_labels:\n",
    "    # Extract nodes of this label\n",
    "    nodes = [n for n in G.nodes if G.nodes[n][\"label\"] == node_label]\n",
    "    \n",
    "    # Identify all possible features for this node type\n",
    "    all_features = set()\n",
    "    for n in nodes:\n",
    "        all_features.update(G.nodes[n].keys())\n",
    "    all_features -= {\"type\"}  # Remove \"type\" field\n",
    "\n",
    "    # Prepare data storage\n",
    "    num_features, cat_features = [], []\n",
    "    cat_feature_encoders = {}  # Store encoders for categorical features\n",
    "    feature_matrix = []\n",
    "    \n",
    "    for n in nodes:\n",
    "        feature_vector = []\n",
    "        for key in all_features:\n",
    "            if key not in G.nodes[n]:  # Handle missing values\n",
    "                feature_vector.append(0)  # Default numeric value\n",
    "            else:\n",
    "                value = G.nodes[n][key]\n",
    "                if isinstance(value, (int, float)):  # Numeric feature\n",
    "                    feature_vector.append(value)\n",
    "                else:  # Categorical feature\n",
    "                    if key not in cat_feature_encoders:\n",
    "                        cat_feature_encoders[key] = OneHotEncoder( handle_unknown=\"ignore\")\n",
    "                    encoded = cat_feature_encoders[key].fit_transform([[value]])[0]\n",
    "                    feature_vector.extend(encoded)\n",
    "\n",
    "        feature_matrix.append(feature_vector)\n",
    "  # Convert numerical features to NumPy array\n",
    "    if num_features:\n",
    "        num_features = np.array(num_features).T\n",
    "        num_features = StandardScaler().fit_transform(num_features)\n",
    "    \n",
    "    # Convert categorical features to NumPy array and concatenate with numerical\n",
    "    if cat_features:\n",
    "        cat_features_array = np.hstack(list(cat_features.values()))\n",
    "    else:\n",
    "        cat_features_array = None\n",
    "\n",
    "    if num_features is not None and cat_features_array is not None:\n",
    "        feature_matrix = np.hstack([num_features, cat_features_array])\n",
    "    elif num_features is not None:\n",
    "        feature_matrix = num_features\n",
    "    elif cat_features_array is not None:\n",
    "        feature_matrix = cat_features_array\n",
    "\n",
    "    # Convert to PyTorch tensor\n",
    "    if len(feature_matrix) > 0:\n",
    "        data[node_label].x = torch.tensor(feature_matrix, dtype=torch.float)\n",
    "\n",
    "    # Store mapping from original node ID to new index\n",
    "    node_mappings[node_label] = {n: i for i, n in enumerate(nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_label in edge_labels:\n",
    "    edge_list = [(str(u), str(v)) for u, v in G.edges if G[u][v][\"label\"] == edge_label]\n",
    "\n",
    "    if not edge_list:\n",
    "        continue\n",
    "\n",
    "    # Validate that the first edge's nodes exist in the graph\n",
    "    src_node, dst_node = edge_list[0]\n",
    "    if src_node not in G.nodes or dst_node not in G.nodes:\n",
    "        print(f\"âš ï¸ Warning: Edge references missing nodes ({src_node}, {dst_node})! Skipping this edge label.\")\n",
    "        continue\n",
    "\n",
    "    src_label, dst_label = G.nodes[src_node][\"label\"], G.nodes[dst_node][\"label\"]\n",
    "\n",
    "    # Skip edges where nodes are not mapped\n",
    "    valid_edges = [\n",
    "        (u, v) for u, v in edge_list if u in node_mappings[src_label] and v in node_mappings[dst_label]\n",
    "    ]\n",
    "\n",
    "    if not valid_edges:\n",
    "        print(f\"âš ï¸ Warning: No valid edges found for edge label {edge_label}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Convert to edge index format\n",
    "    edge_index = torch.tensor([\n",
    "        [node_mappings[src_label][u], node_mappings[dst_label][v]]\n",
    "        for u, v in valid_edges\n",
    "    ], dtype=torch.long).T\n",
    "\n",
    "    # Store in data object\n",
    "    data[(src_label, edge_label, dst_label)].edge_index = edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  (:Movie, PRODUCED, :Person)={ edge_index=[2, 2] },\n",
      "  (:Movie, RELEASED, :Cinema)={ edge_index=[2, 644] },\n",
      "  (:Movie, ACTED_IN, :Person)={ edge_index=[2, 99] },\n",
      "  (:Movie, REVIEWED, :Person)={ edge_index=[2, 9] },\n",
      "  (:Movie, DIRECTED, :Person)={ edge_index=[2, 23] },\n",
      "  (:Person, WROTE, :Movie)={ edge_index=[2, 5] },\n",
      "  (:Person, FOLLOWS, :Person)={ edge_index=[2, 3] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# âœ… Dataset is ready!\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data, \"data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, GATConv, Linear\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.transforms import ToUndirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert graph to undirected (optional but useful)\n",
    "data = ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Define HeteroGAT for Node Classification\n",
    "class HeteroGATNodeClassifier(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            edge_type: GATConv((-1, -1), hidden_channels, heads=2, concat=True,add_self_loops=False)\n",
    "            for edge_type in metadata[1]\n",
    "        })\n",
    "        self.conv2 = HeteroConv({\n",
    "            edge_type: GATConv((-1, -1), out_channels, heads=1, concat=False,add_self_loops=False)\n",
    "            for edge_type in metadata[1]\n",
    "        })\n",
    "        self.classifier = Linear(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.elu(x) for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return self.classifier(x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Define HeteroGAT for Link Prediction\n",
    "class HeteroGATLinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            edge_type: GATConv((-1, -1), hidden_channels, heads=2, concat=True,add_self_loops=False)\n",
    "            for edge_type in metadata[1]\n",
    "        })\n",
    "        self.conv2 = HeteroConv({\n",
    "            edge_type: GATConv((-1, -1), hidden_channels, heads=1, concat=False,add_self_loops=False)\n",
    "            for edge_type in metadata[1]\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.elu(x) for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "    def predict_link(self, x_dict, edge_label_index):\n",
    "        src, dst = edge_label_index\n",
    "        return (x_dict[src] * x_dict[dst]).sum(dim=-1).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¥ Initialize Models\n",
    "hidden_channels = 64\n",
    "num_classes = 3  # Adjust based on your node classification task\n",
    "\n",
    "node_model = HeteroGATNodeClassifier(data.metadata(), hidden_channels, num_classes)\n",
    "link_model = HeteroGATLinkPredictor(data.metadata(), hidden_channels)\n",
    "\n",
    "# Optimizers\n",
    "node_optimizer = torch.optim.Adam(node_model.parameters(), lr=0.005)\n",
    "link_optimizer = torch.optim.Adam(link_model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¥ Node Classification Training Loop\n",
    "def train_node_classifier():\n",
    "    node_model.train()\n",
    "    node_optimizer.zero_grad()\n",
    "\n",
    "    out = node_model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data[\"Movie\"].train_mask  # Example: Classify Movies\n",
    "    loss = F.cross_entropy(out[\"Movie\"][mask], data[\"Movie\"].y[mask])\n",
    "\n",
    "    loss.backward()\n",
    "    node_optimizer.step()\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¥ Link Prediction Training Loop\n",
    "def train_link_predictor():\n",
    "    link_model.train()\n",
    "    link_optimizer.zero_grad()\n",
    "\n",
    "    x_dict = link_model(data.x_dict, data.edge_index_dict)\n",
    "    edge_label_index = data[\"Movie\", \"ACTED_IN\", \"Person\"].edge_index\n",
    "\n",
    "    pred = link_model.predict_link(x_dict, edge_label_index)\n",
    "    target = torch.ones(pred.shape)  # Positive links\n",
    "\n",
    "    loss = F.binary_cross_entropy(pred, target)\n",
    "    loss.backward()\n",
    "    link_optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HeteroData' has no attribute 'node_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure every node type has an `x` feature\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_labels\u001b[49m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data[node_label]:\n\u001b[1;32m      4\u001b[0m         num_nodes \u001b[38;5;241m=\u001b[39m data[node_label]\u001b[38;5;241m.\u001b[39mnum_nodes\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py:162\u001b[0m, in \u001b[0;36mHeteroData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_dict$\u001b[39m\u001b[38;5;124m'\u001b[39m, key)):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect(key[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HeteroData' has no attribute 'node_labels'"
     ]
    }
   ],
   "source": [
    "# Ensure every node type has an `x` feature\n",
    "for node_label in data.node_labels:\n",
    "    if \"x\" not in data[node_label]:\n",
    "        num_nodes = data[node_label].num_nodes\n",
    "        feature_dim = 64  # Adjust based on your model input size\n",
    "        print(f\"âš ï¸ Warning: No features found for {node_label}. Assigning random features.\")\n",
    "        data[node_label].x = torch.randn(num_nodes, feature_dim)  # Initialize with random embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Tried to collect 'x' but did not find any occurrences of it in any node and/or edge type\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ðŸ”¥ Training Execution\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     node_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_node_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     link_loss \u001b[38;5;241m=\u001b[39m train_link_predictor()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m, in \u001b[0;36mtrain_node_classifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m node_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m node_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 6\u001b[0m out \u001b[38;5;241m=\u001b[39m node_model(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m, data\u001b[38;5;241m.\u001b[39medge_index_dict)\n\u001b[1;32m      7\u001b[0m mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovie\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtrain_mask  \u001b[38;5;66;03m# Example: Classify Movies\u001b[39;00m\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovie\u001b[39m\u001b[38;5;124m\"\u001b[39m][mask], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovie\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39my[mask])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py:161\u001b[0m, in \u001b[0;36mHeteroData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_global_store, key)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_dict$\u001b[39m\u001b[38;5;124m'\u001b[39m, key)):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py:565\u001b[0m, in \u001b[0;36mHeteroData.collect\u001b[0;34m(self, key, allow_empty)\u001b[0m\n\u001b[1;32m    563\u001b[0m         mapping[subtype] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(store, key)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_empty \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapping) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to collect \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but did not find any \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moccurrences of it in any node and/or edge type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mapping\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Tried to collect 'x' but did not find any occurrences of it in any node and/or edge type\""
     ]
    }
   ],
   "source": [
    "# ðŸ”¥ Training Execution\n",
    "for epoch in range(50):\n",
    "    node_loss = train_node_classifier()\n",
    "    link_loss = train_link_predictor()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Node Loss = {node_loss:.4f}, Link Loss = {link_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¥ Evaluation for Node Classification\n",
    "node_model.eval()\n",
    "out = node_model(data.x_dict, data.edge_index_dict)\n",
    "pred = out[\"Movie\"].argmax(dim=-1)\n",
    "accuracy = (pred[data[\"Movie\"].test_mask] == data[\"Movie\"].y[data[\"Movie\"].test_mask]).sum() / data[\"Movie\"].test_mask.sum()\n",
    "print(f\"Node Classification Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¥ Evaluation for Link Prediction\n",
    "link_model.eval()\n",
    "x_dict = link_model(data.x_dict, data.edge_index_dict)\n",
    "edge_label_index = data[\"Movie\", \"ACTED_IN\", \"Person\"].edge_index\n",
    "pred = link_model.predict_link(x_dict, edge_label_index)\n",
    "\n",
    "print(f\"Example Link Predictions: {pred[:5]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
